{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa7c2d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동영상 특징추출 파일 목록: ['최소데이터\\\\000\\\\feature\\\\000-001.csv', '최소데이터\\\\000\\\\feature\\\\000-002.csv', '최소데이터\\\\000\\\\feature\\\\000-003.csv', '최소데이터\\\\000\\\\feature\\\\000-004.csv', '최소데이터\\\\000\\\\feature\\\\000-005.csv']\n",
      "\n",
      "이미지 파일 목록: ['최소데이터\\\\000\\\\picture\\\\000-ang-00.JPG', '최소데이터\\\\000\\\\picture\\\\000-ang-01.JPG', '최소데이터\\\\000\\\\picture\\\\000-ang-02.JPG', '최소데이터\\\\000\\\\picture\\\\000-ang-03.JPG', '최소데이터\\\\000\\\\picture\\\\000-ang-04.JPG']\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 128, 128, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 31, 4)]              0         []                            \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 126, 126, 32)         896       ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 31, 64)               17664     ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 63, 63, 32)           0         ['conv2d_1[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 1984)                 0         ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)         (None, 127008)               0         ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 128992)               0         ['flatten_2[0][0]',           \n",
      " )                                                                   'flatten_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 128)                  1651110   ['concatenate_1[0][0]']       \n",
      "                                                          4                                       \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 7)                    903       ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16530567 (63.06 MB)\n",
      "Trainable params: 16530567 (63.06 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, concatenate, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def get_file_paths(directory, file_type):\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(file_type):\n",
    "                file_paths.append(os.path.join(root, file))\n",
    "    return file_paths\n",
    "\n",
    "movie_data_csv = get_file_paths(\"최소데이터\", \"csv\")\n",
    "image_data = get_file_paths(\"최소데이터\", \".JPG\")\n",
    "\n",
    "print(\"동영상 특징추출 파일 목록:\", movie_data_csv[:5])\n",
    "print(\"\\n이미지 파일 목록:\", image_data[:5])\n",
    "\n",
    "def find_min_rows(file_paths):\n",
    "    min_rows = float('inf')\n",
    "    for file_path in file_paths:\n",
    "        data = pd.read_csv(file_path)\n",
    "        if len(data) < min_rows:\n",
    "            min_rows = len(data)\n",
    "    return min_rows\n",
    "\n",
    "def process_csv_files(file_paths, num_rows, chunksize=10000):\n",
    "    processed_data = []\n",
    "    for file_path in file_paths:\n",
    "        data_list = []\n",
    "        total_rows = 0\n",
    "\n",
    "        for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
    "            total_rows += len(chunk)\n",
    "            if total_rows <= num_rows:\n",
    "                data_list.append(chunk)\n",
    "            else:\n",
    "                remaining_rows = num_rows - (total_rows - len(chunk))\n",
    "                data_list.append(chunk.iloc[:remaining_rows])\n",
    "                break\n",
    "\n",
    "        combined_data = pd.concat(data_list)\n",
    "\n",
    "        # 패딩 추가\n",
    "        if len(combined_data) < num_rows:\n",
    "            padding = pd.DataFrame(np.zeros((num_rows - len(combined_data), combined_data.shape[1])), columns=combined_data.columns)\n",
    "            combined_data = pd.concat([combined_data, padding])\n",
    "\n",
    "        processed_data.append(combined_data)\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "min_rows = find_min_rows(movie_data_csv)\n",
    "processed_data = process_csv_files(movie_data_csv, min_rows, chunksize=10000)\n",
    "lstm_data = np.array([data.values for data in processed_data], dtype=np.float32)\n",
    "\n",
    "# CNN 모델을 위한 데이터 전처리\n",
    "cnn_data = np.array([img_to_array(load_img(file, target_size=(128, 128))) for file in image_data], dtype=np.float32)\n",
    "cnn_input_shape = cnn_data.shape[1:]\n",
    "\n",
    "# LSTM 모델을 위한 데이터 전처리\n",
    "lstm_input_shape = lstm_data.shape[1:]\n",
    "\n",
    "# LSTM 모델 정의\n",
    "def create_lstm_model(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = LSTM(64, return_sequences=True)(input_layer)\n",
    "    x = Flatten()(x)\n",
    "    return Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "# CNN 모델 정의\n",
    "def create_cnn_model(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Conv2D(32, kernel_size=(3, 3), activation='relu')(input_layer)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    return Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "# 감정 클래스를 숫자로 매핑\n",
    "emotion_classes = {\"ang\": 0, \"dis\": 1, \"neu\": 2, \"sad\": 3, \"sur\": 4, \"fea\": 5, \"hap\": 6}\n",
    "\n",
    "# 각 모달에 대한 모델 생성\n",
    "lstm_model = create_lstm_model(lstm_input_shape)\n",
    "cnn_model = create_cnn_model((128, 128, 3))\n",
    "#각 모달 모델의 출력을 결합\n",
    "lstm_output = lstm_model.output\n",
    "cnn_output = cnn_model.output\n",
    "#각 모달 모델의 출력을 결합하여 최종 예측 수행하는 모델 정의\n",
    "combined_output = concatenate([lstm_output, cnn_output])\n",
    "x = Dense(128, activation='relu')(combined_output)\n",
    "final_output = Dense(len(emotion_classes), activation='softmax')(x)\n",
    "#최종 모델 정의\n",
    "model = Model(inputs=[lstm_model.input, cnn_model.input], outputs=final_output)\n",
    "\n",
    "#모델 컴파일\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#모델 요약\n",
    "model.summary()\n",
    "#훈련 데이터와 테스트 데이터 분리\n",
    "train_lstm, test_lstm, train_cnn, test_cnn = train_test_split(\n",
    "lstm_data, cnn_data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "#레이블 준비 (실제 레이블을 사용해야 함)\n",
    "#예시를 위해 랜덤한 레이블을 생성합니다. 실제 데이터에서는 이 부분을 수정해야 합니다.\n",
    "train_labels = np.random.randint(0, len(emotion_classes), size=(len(train_lstm),))\n",
    "test_labels = np.random.randint(0, len(emotion_classes), size=(len(test_lstm),))\n",
    "\n",
    "#원-핫 인코딩으로 레이블 변환\n",
    "train_labels = to_categorical(train_labels, num_classes=len(emotion_classes))\n",
    "test_labels = to_categorical(test_labels, num_classes=len(emotion_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8f8cc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 81ms/step - loss: 3830.6782 - accuracy: 0.1500\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 6563.9155 - accuracy: 0.2000\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 6383.3906 - accuracy: 0.1000\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 4845.8086 - accuracy: 0.1500\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 2829.3540 - accuracy: 0.1875\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 1386.7795 - accuracy: 0.2250\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 786.6378 - accuracy: 0.1625\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 288.4865 - accuracy: 0.2500\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 177.6789 - accuracy: 0.1500\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 109.8408 - accuracy: 0.3625\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 55.4632 - accuracy: 0.4375\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 21.5212 - accuracy: 0.6875\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 21.3881 - accuracy: 0.6500\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 17.0847 - accuracy: 0.6625\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 5.5634 - accuracy: 0.8125\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 2.5086 - accuracy: 0.8875\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 1.2655 - accuracy: 0.9375\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.7377 - accuracy: 0.9625\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.5563 - accuracy: 0.9625\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0122 - accuracy: 0.9875\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 1.6241e-06 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2129 - accuracy: 0.9875\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.4901e-09 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.9802e-09 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 8.9407e-09 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 1.0431e-08 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.4901e-08 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.6391e-08 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 1.9371e-08 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.0862e-08 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.2352e-08 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 2.2352e-08 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.3842e-08 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 2.3842e-08 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 2.3842e-08 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 2.3842e-08 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 1.4901e-09 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 2.9802e-09 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c6d958f580>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 훈련\n",
    "model.fit([train_lstm, train_cnn], train_labels, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97fa734d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 178ms/step - loss: 42.7651 - accuracy: 0.2000\n",
      "테스트 데이터 정확도: 20.00%\n"
     ]
    }
   ],
   "source": [
    "#모델 평가\n",
    "accuracy = model.evaluate([test_lstm, test_cnn], test_labels)\n",
    "print(f\"테스트 데이터 정확도: {accuracy[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c672bfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 150ms/step\n",
      "Sample 0: Actual Class - 5, Predicted Class - 2\n",
      "Sample 1: Actual Class - 5, Predicted Class - 2\n",
      "Sample 2: Actual Class - 4, Predicted Class - 2\n",
      "Sample 3: Actual Class - 1, Predicted Class - 3\n",
      "Sample 4: Actual Class - 1, Predicted Class - 2\n",
      "Sample 5: Actual Class - 5, Predicted Class - 5\n",
      "Sample 6: Actual Class - 5, Predicted Class - 3\n",
      "Sample 7: Actual Class - 4, Predicted Class - 6\n",
      "Sample 8: Actual Class - 2, Predicted Class - 2\n",
      "Sample 9: Actual Class - 6, Predicted Class - 2\n",
      "Sample 10: Actual Class - 1, Predicted Class - 3\n",
      "Sample 11: Actual Class - 2, Predicted Class - 2\n",
      "Sample 12: Actual Class - 3, Predicted Class - 4\n",
      "Sample 13: Actual Class - 1, Predicted Class - 5\n",
      "Sample 14: Actual Class - 2, Predicted Class - 2\n",
      "Sample 15: Actual Class - 5, Predicted Class - 3\n",
      "Sample 16: Actual Class - 0, Predicted Class - 6\n",
      "Sample 17: Actual Class - 6, Predicted Class - 2\n",
      "Sample 18: Actual Class - 6, Predicted Class - 2\n",
      "Sample 19: Actual Class - 1, Predicted Class - 3\n"
     ]
    }
   ],
   "source": [
    "#테스트 데이터에 대한 예측 수행\n",
    "predicted_labels = model.predict([test_lstm, test_cnn])\n",
    "\n",
    "#예측 결과와 실제 레이블 비교 (옵션)\n",
    "for i in range(len(test_lstm)):\n",
    "    actual_class = np.argmax(test_labels[i])\n",
    "    predicted_class = np.argmax(predicted_labels[i])\n",
    "    print(f\"Sample {i}: Actual Class - {actual_class}, Predicted Class - {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a22264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
